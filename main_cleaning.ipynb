{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed99698",
   "metadata": {},
   "source": [
    "### Main data cleaning\n",
    "\n",
    "The data cleaning pipeline has four stages:\n",
    "1. remove outliers using a) interquartile ratio with cutoff of 2.5 and b) \"natural\" bounds from other research or experimental design\n",
    "2. standardize continuous variables using StandardScaler\n",
    "3. calculate interaction terms between anxiety and depression\n",
    "4. stratify bad life events (top/bottom 15%) and (maybe) calculate interactions between bad and good life events\n",
    "5. propogate fixed demographic variables captured at baseline across subsequent timelines\n",
    "\n",
    "The target variables for each step are specified in `data_cleaning.py` and interaction functions are defined in `interactions.py`. It is straightforward to edit either of these files to add/remove variables and interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "062767c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "import data_cleaning\n",
    "import interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c943c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bd41a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw data\n",
    "raw_data_file_name = \"RAW_ABCD_5.0_panel_20240805.csv\"\n",
    "data = pd.read_csv(output_dir + raw_data_file_name, index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e154038",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15ba426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for IQR outlier removal\n",
    "outliers = list(data_cleaning.outlier_vars.keys())\n",
    "data[outliers] = data_cleaning.remove_outlier_IQR(data[outliers], cutoff=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5aca7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logical/prior bounds outlier removal\n",
    "for var, bounds in data_cleaning.outlier_vars.items():\n",
    "    data[var] = data_cleaning.remove_outlier_bounds(data[var], bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efa69f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = data.query('time == 0').reset_index(drop=True)\n",
    "t1 = data.query('time == 1').reset_index(drop=True)\n",
    "t2 = data.query('time == 2').reset_index(drop=True)\n",
    "t3 = data.query('time == 3').reset_index(drop=True)\n",
    "t4 = data.query('time == 4').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed46b635",
   "metadata": {},
   "source": [
    "### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acbceba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "t0[data_cleaning.standardize_vars] = data_cleaning.standardize(t0[data_cleaning.standardize_vars])\n",
    "t1[data_cleaning.standardize_vars] = data_cleaning.standardize(t1[data_cleaning.standardize_vars])\n",
    "t2[data_cleaning.standardize_vars] = data_cleaning.standardize(t2[data_cleaning.standardize_vars])\n",
    "t3[data_cleaning.standardize_vars] = data_cleaning.standardize(t3[data_cleaning.standardize_vars])\n",
    "t4[data_cleaning.standardize_vars] = data_cleaning.standardize(t4[data_cleaning.standardize_vars])\n",
    "\n",
    "# Errors mean that certain columns are all zero?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c403d6",
   "metadata": {},
   "source": [
    "### Calculate interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4223a7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['depanx_c'] = depanx_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['depadhd_c'] = depadhd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['anxadhd_c'] = anxadhd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['anxocd_c'] = anxocd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['crysflu_c'] = crysflu_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['depanx_c'] = depanx_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['depadhd_c'] = depadhd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['anxadhd_c'] = anxadhd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['anxocd_c'] = anxocd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/numpy/lib/_nanfunctions_impl.py:1424: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['crysflu_c'] = crysflu_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['depanx_c'] = depanx_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['depadhd_c'] = depadhd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['anxadhd_c'] = anxadhd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['anxocd_c'] = anxocd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['crysflu_c'] = crysflu_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['depanx_c'] = depanx_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['depadhd_c'] = depadhd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['anxadhd_c'] = anxadhd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['anxocd_c'] = anxocd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Library/Python/3.9/lib/python/site-packages/numpy/lib/_nanfunctions_impl.py:1424: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['crysflu_c'] = crysflu_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['depanx_c'] = depanx_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['depadhd_c'] = depadhd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['anxadhd_c'] = anxadhd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['anxocd_c'] = anxocd_interaction(df, lower, upper)\n",
      "/Users/Raphael/Desktop/GabLab/ABCD/extraction_code/interactions.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['crysflu_c'] = crysflu_interaction(df, lower, upper)\n"
     ]
    }
   ],
   "source": [
    "t0 = interactions.add_interactions(t0).copy()\n",
    "t1 = interactions.add_interactions(t1).copy()\n",
    "t2 = interactions.add_interactions(t2).copy()\n",
    "t3 = interactions.add_interactions(t3).copy()\n",
    "t4 = interactions.add_interactions(t4).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a841725",
   "metadata": {},
   "source": [
    "### Propogate fixed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf71f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = t0[['subject'] + data_cleaning.fixed_vars].copy()\n",
    "t0.drop(columns=data_cleaning.fixed_vars, inplace=True)\n",
    "t1.drop(columns=data_cleaning.fixed_vars, inplace=True)\n",
    "t2.drop(columns=data_cleaning.fixed_vars, inplace=True)\n",
    "t3.drop(columns=data_cleaning.fixed_vars, inplace=True)\n",
    "t4.drop(columns=data_cleaning.fixed_vars, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47fbe0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = pd.merge(t0, fixed, on='subject', how='outer')\n",
    "t1 = pd.merge(t1, fixed, on='subject', how='outer')\n",
    "t2 = pd.merge(t2, fixed, on='subject', how='outer')\n",
    "t3 = pd.merge(t3, fixed, on='subject', how='outer')\n",
    "t4 = pd.merge(t4, fixed, on='subject', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98721278",
   "metadata": {},
   "source": [
    "### Join time points and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6b0f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_date = date.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9b86f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean_data = pd.concat([t0, t1, t2, t3, t4])\n",
    "final_clean_data = final_clean_data.convert_dtypes(convert_string=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9082aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final data has shape: (59338, 590)\n",
      "File saved\n"
     ]
    }
   ],
   "source": [
    "print(\"final data has shape: \" + str(final_clean_data.shape))\n",
    "final_clean_data.to_csv(f'{output_dir}CLEAN_ABCD_5.1_panel_{todays_date}.csv')\n",
    "print(\"File saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
